{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing networkx and graph-tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular graph analysis libraries for Python are `networkx` and `graph-tool`. While `networkx` offers a very accessible Python API and a large variety of out-of-the-box graph algorithms, `graph-tool` is compiled down into C and claims to offer substantial performance gains. I want to validate those claims here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import graph_tool.all as gt\n",
    "\n",
    "import cc_graph_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "edges = [(0, 1)]\n",
    "for i in range(2, n):\n",
    "    edges.append((i, np.random.randint(i)))\n",
    "\n",
    "nxG = nx.Graph()\n",
    "nxG.add_nodes_from(range(n))\n",
    "nxG.add_edges_from(edges)\n",
    "\n",
    "gtG = gt.Graph(directed=False)\n",
    "gtG.add_vertex(n)\n",
    "gtG.add_edge_list(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_method(name, func, arg, template=\"{:<20}{:>10.3f} s\"):\n",
    "    start = time.time()\n",
    "    func(arg)\n",
    "    end = time.time()\n",
    "    print(template.format(name, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating graph-tool PageRank\n",
      "gt PageRank              0.005 s\n",
      "\n",
      "Evaluating networkx PageRank Algorithms\n",
      "nx PageRank              0.574 s\n",
      "nx PageRank (Numpy)     55.845 s\n",
      "nx PageRank (Scipy)      0.027 s\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating graph-tool PageRank\")\n",
    "time_method(\"gt PageRank\", gt.pagerank, gtG)\n",
    "print()\n",
    "print(\"Evaluating networkx PageRank Algorithms\")\n",
    "time_method(\"nx PageRank\", nx.pagerank, nxG)\n",
    "time_method(\"nx PageRank (Numpy)\", nx.pagerank_numpy, nxG)\n",
    "time_method(\"nx PageRank (Scipy)\", nx.pagerank_scipy, nxG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`graph-tool` definitely takes the cake on this one. To be honest, I'm unsure why the `nx.pagerank_numpy` algorithm turns out to run the slowest. Maybe it's not optimized for sparse graphs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Vertex Betweeness Centrality\n",
      "gt Betweenness Centrality     0.396 s\n",
      "nx Betweeeness Centrality    65.690 s\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparing Vertex Betweeness Centrality\")\n",
    "time_method(\"gt Betweenness Centrality\", gt.betweenness, gtG)\n",
    "time_method(\"nx Betweeeness Centrality\", nx.betweenness_centrality, nxG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing K-Cores\n",
      "gt kcores                0.000 s\n",
      "nx kcores                0.016 s\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparing K-Cores\")\n",
    "time_method(\"gt kcores\", gt.kcore_decomposition, gtG)\n",
    "# Note: the nx.k_core actually returns the subgraph for a specified k; we want to get for all k's for a fair comparison\n",
    "time_method(\"nx kcores\", nx.core_number, nxG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the above tests that (at least for sparse, small graphs that can fit in RAM), `graph-tool` consistenly out-performs `networkx`. My recommendation is that we primarily use `graph-tool` once we start performing these computations on our dataset and reserve `networkx` for exploratory prototyping and for algorithms not present in the `graph-tool` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing graph on 100 vertices took 0.016 s\n",
      "PageRank took 0.001 s\n",
      "constructing graph on 500 vertices took 0.044 s\n",
      "PageRank took 0.001 s\n",
      "constructing graph on 1000 vertices took 0.098 s\n",
      "PageRank took 0.001 s\n",
      "constructing graph on 5000 vertices took 0.398 s\n",
      "PageRank took 0.005 s\n",
      "constructing graph on 10000 vertices took 0.684 s\n",
      "PageRank took 0.013 s\n",
      "constructing graph on 50000 vertices took 3.214 s\n",
      "PageRank took 0.119 s\n",
      "constructing graph on 100000 vertices took 6.319 s\n",
      "PageRank took 0.265 s\n",
      "constructing graph on 500000 vertices took 31.603 s\n",
      "PageRank took 3.646 s\n"
     ]
    }
   ],
   "source": [
    "def generate_edge_list(v, ev_ratio=20):\n",
    "    \"\"\"Creates an edge lists to construct a graph-tool graph.\n",
    "    \n",
    "    Parameters:\n",
    "    v: number of vertices\n",
    "    ev_ratio: ratio of edges to vertices, equals 0.5 * average degree\n",
    "    \n",
    "    Returns:\n",
    "    list of edges (v1, v2)\n",
    "    \"\"\"\n",
    "    edges = [(0, 1)]\n",
    "    for i in range(2, v):\n",
    "        for _ in range(ev_ratio):\n",
    "            edges.append((i, np.random.randint(i)))\n",
    "    return edges\n",
    "\n",
    "for v in [1e2, 5e2, 1e3, 5e3, 1e4, 5e4, 1e5, 5e5]:\n",
    "    v = int(v)\n",
    "    tic = time.time()\n",
    "    gtG = gt.Graph(directed=True)\n",
    "    gtG.add_vertex(v)\n",
    "    gtG.add_edge_list(generate_edge_list(v))\n",
    "    toc = time.time()\n",
    "    print(f'constructing graph on {v} vertices took {(toc - tic):.3f} s')\n",
    "    \n",
    "    tic = time.time()\n",
    "    _ = gt.pagerank(gtG)\n",
    "    toc = time.time()\n",
    "    print(f'PageRank took {(toc-tic):.3f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import graph_tool.all as gt\n",
    "\n",
    "import cc_graph_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fdg_input_file.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "nodes = data['nodes']\n",
    "links = data['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "\n",
    "def memory_limit(limit):\n",
    "    \"\"\"prevents python from using more than LIMIT bytes\"\"\"\n",
    "    soft, hard = resource.getrlimit(resource.RLIMIT_AS)\n",
    "    resource.setrlimit(resource.RLIMIT_AS, (limit, hard))\n",
    "    \n",
    "memory_limit(4*1024*1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30000 nodes is around the limit when we \n",
    "# restrict to 4GB of memory usage\n",
    "\n",
    "limit = 30000\n",
    "\n",
    "gtG = gt.Graph(directed=True)\n",
    "gtG.vertex_properties['id'] = gtG.new_vertex_property('string')\n",
    "vertices = dict()\n",
    "for node in nodes[:limit]:\n",
    "    v = gtG.add_vertex()\n",
    "    vertices[node['id']] = v\n",
    "    gtG.vertex_properties['id'][v] = node['id']\n",
    "edges = []\n",
    "for link in links:\n",
    "    if link['source'] in vertices and link['target'] in vertices:\n",
    "        src = vertices[link['source']]\n",
    "        dest = vertices[link['target']]\n",
    "        for i in range(link['value']):\n",
    "            gtG.add_edge(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, to my knowledge, neither of these libraries are accessing the GPU. Below, I experiment with one of the more promising GPU graph analytics libraries, [`cuGraph`](https://github.com/rapidsai/cugraph) from [rapids.ai](https://rapids.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is modified from a Rapids AI [tutorial](https://github.com/rapidsai/cugraph/blob/branch-0.13/notebooks/centrality/Katz.ipynb). **Requires NVIDIA Pascal or newer GPU architecture**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sohom/miniconda3/envs/linked_commons/lib/python3.8/site-packages/cudf/utils/gpu_utils.py:92: UserWarning: You will need a GPU with NVIDIA Pascalâ„¢ or newer architecture\n",
      "Detected GPU 0: GeForce GTX 950M \n",
      "Detected Compute Capability: 5.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cugraph\n",
    "import cudf\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "tol = 1e-5\n",
    "\n",
    "datafile = '../karate-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = cudf.read_csv(datafile, delimiter='\\t', names=['src', 'dst'], dtype=['int32', 'int32'] )\n",
    "\n",
    "G = cugraph.Graph()\n",
    "G.from_cudf_edgelist(gdf, source='src', destination='dst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_page = cugraph.pagerank(G)\n",
    "\n",
    "for i in range(len(df_page)):\n",
    "    print(\"vertex \" + str(df_page['vertex'].iloc[i]) + \" PageRank is \" + str(df_page['pagerank'].iloc[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('linked_commons': conda)",
   "language": "python",
   "name": "python38564bitlinkedcommonsconda8c925ff8f8704234b7d011f0d1aa2749"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
